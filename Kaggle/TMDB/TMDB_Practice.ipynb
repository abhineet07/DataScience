{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\n# Libraries\n\nimport numpy as np\nimport pandas as pd\npd.set_option('max_columns', None)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nplt.style.use('ggplot')\nimport datetime\nimport lightgbm as lgb\nfrom scipy import stats\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.model_selection import train_test_split, KFold\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.preprocessing import StandardScaler\nstop = set(stopwords.words('english'))\nimport os\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score\nimport json\nimport ast\nimport eli5\nimport shap\nfrom catboost import CatBoostRegressor\nfrom urllib.request import urlopen\nfrom PIL import Image\nfrom sklearn.preprocessing import LabelEncoder\nimport time\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import linear_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/tmdb-box-office-prediction/train.csv')\ntest = pd.read_csv('../input/tmdb-box-office-prediction/test.csv')\n\n# from this kernel: https://www.kaggle.com/gravix/gradient-in-a-box\ndict_columns = ['belongs_to_collection', 'genres', 'production_companies',\n                'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\n\ndef text_to_dict(df):\n    for column in dict_columns:\n        df[column] = df[column].apply(lambda x: {} if pd.isna(x) else ast.literal_eval(x) )\n    return df\n        \ntrain = text_to_dict(train)\ntest = text_to_dict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape\n\n# we have 3000 samples in the train data set and 23 columns (22 features)\n# some columns contains list of dictionaries","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets extract data from 'belongs_to_collection'\nfor i, e in enumerate(train['belongs_to_collection'][:5]):\n    print(i, e)\n    \n# we can see some of these are list of dictionaries and some are empty","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets calculate how many are empty and non-empty\nprint(train['belongs_to_collection'].apply(lambda x: type(x) if x != {} else 0).unique())\ntrain['belongs_to_collection'].apply(lambda x: len(x) if x!={} else 0).value_counts()\n\n# there are 2096 values which are empty","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['collection_name'] = train['belongs_to_collection'].apply(lambda x: x[0]['name'] if x!={} else 0)\ntrain['has_collection'] = train['belongs_to_collection'].apply(lambda x: len(x) if x!={} else 0)\nprint(train['collection_name'])\n\ntest['collection_name'] = test['belongs_to_collection'].apply(lambda x: x[0]['name'] if x!={} else 0)\ntest['has_collection'] = test['belongs_to_collection'].apply(lambda x: len(x) if x!={} else 0)\n\ntrain = train.drop(['belongs_to_collection'], axis=1)\ntest = test.drop(['belongs_to_collection'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Genres**"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, e in enumerate(train['genres'][:5]):\n    print(i, e)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we will find number of genres in the films, i.e. their count"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of Genres')\n\ntrain['genres'].apply(lambda x: len(x) if x!={} else 0).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# all the genres\n\nlist_of_genres = list(train['genres'].apply(lambda x: [i['name'] for i in x] if x!={} else []).values)\nlist_of_genres[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# generating wordcloud\nplt.figure(figsize = (12, 8))\ntext = ' '.join([i for j in list_of_genres for i in j])\n\n# printing first 100 characters of the text\nprint(text[:100])\n\nwordcloud = WordCloud(max_font_size=None, background_color='white', collocations=False, width=1000, height=1000).generate(text)\nplt.imshow(wordcloud)\nplt.title('Top Genres')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Drama, Comedy, Thriller are most popular genres"},{"metadata":{"trusted":true},"cell_type":"code","source":"Counter([i for j in list_of_genres for i in j]).most_common()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create columns for top 15 most popular genres"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['num_genres'] = train['genres'].apply(lambda x: len(x) if x!={} else 0)\ntrain['all_genres'] = train['genres'].apply(lambda x: ' '.join(sorted(i['name'] for i in x)) if x!={} else '')\nprint(train['all_genres'][:5])\n\ntop_genres = [m[0] for m in Counter([i for j in list_of_genres for i in j]).most_common(15)]\nprint(top_genres)\n\nfor g in top_genres:\n    train['genre_' + g] = train['all_genres'].apply(lambda x: 1 if g in x else 0)\n    \n# test \ntest['num_genres'] = test['genres'].apply(lambda x: len(x) if x!={} else 0)\ntest['all_genres'] = test['genres'].apply(lambda x: ' '.join(sorted(i['name'] for i in x)) if x!={} else '')\nfor g in top_genres:\n    test['genre_' + g] = test['all_genres'].apply(lambda x: 1 if g in x else 0)\n    \ntrain = train.drop(['genres'], axis=1)\ntest = test.drop(['genres'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Production Companies**"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, e in enumerate(train['production_companies'][:5]):\n    print(i, e)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of production companies in the film\")\nprint(\"Production companies  ->  no. of films\")\ntrain['production_companies'].apply(lambda x: len(x) if x!={} else 0).value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of films have 1-2 production companies, sometimes 3-4. But there are films with 10+ companies! Let's have a look at some of them."},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['production_companies'].apply(lambda x: len(x) if x!={} else 0) > 11]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_companies = list(train['production_companies'].apply(lambda x: [i['name'] for i in x] if x!={} else []).values)\nlist_of_companies[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 30 most common production companies\nCounter([i for j in list_of_companies for i in j]).most_common(30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train\ntrain['num_companies'] = train['production_companies'].apply(lambda x: len(x) if x!={} else 0)\ntrain['all_production_companies'] = train['production_companies'].apply(lambda x: ' '.join(sorted(i['name'] for i in x) if x!={} else ''))\ntop_companies = [m[0] for m in Counter([i for j in list_of_companies for i in j]).most_common(30)]\nfor company in top_companies:\n    train['production_company_' + company] = train['all_production_companies'].apply(lambda x: 1 if company in x else 0)\n    \n# test\ntest['num_companies'] = test['production_companies'].apply(lambda x: len(x) if x!={} else 0)\ntest['all_production_companies'] = test['production_companies'].apply(lambda x: ' '.join(sorted(i['name'] for i in x) if x!={} else ''))\nfor company in top_companies:\n    test['production_company_' + company] = test['all_production_companies'].apply(lambda x: 1 if company in x else 0)\n    \n# dropping production_companies column\ntrain = train.drop(['production_companies'], axis=1)\ntest = test.drop(['production_companies'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Production Countries**"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, e in enumerate(train['production_countries'][:5]):\n    print(i, e)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of production counties in films\")\ntrain['production_countries'].apply(lambda x: len(x) if x!={} else 0).value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so normally the films are produced by one country, but there are films with more than 2 production films"},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_countries = list(train['production_countries'].apply(lambda x: [i['name'] for i in x] if x!={} else []).values)\nprint(list_of_countries[:5])\nCounter([i for j in list_of_countries for i in j]).most_common(25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train\ntrain['num_countries'] = train['production_countries'].apply(lambda x: len(x) if x!={} else 0)\ntrain['all_production_countries'] = train['production_countries'].apply(lambda x: ' '.join(sorted(i['name'] for i in x)) if x!={} else '')\ntop_countries = [m[0] for m in Counter([i for j in list_of_countries for i in j]).most_common(25)]\nfor country in top_countries:\n    train['country_' + country] = train['all_production_countries'].apply(lambda x: 1 if country in x else 0)\n    \n# test\ntest['num_countries'] = test['production_countries'].apply(lambda x: len(x) if x!={} else 0)\ntest['all_production_countries'] = test['production_countries'].apply(lambda x: ' '.join(sorted(i['name'] for i in x)) if x!={} else '')\nfor country in top_countries:\n    test['country_' + country] = test['all_production_countries'].apply(lambda x: 1 if country in x else 0)\n    \n# dropping production countries column\ntrain = train.drop(['production_countries'], axis=1)\ntest = test.drop(['production_countries'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Spoken Languages**"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, e in enumerate(train['spoken_languages'][:5]):\n    print(i, e)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of spoken languages in films')\ntrain['spoken_languages'].apply(lambda x: len(x) if x != {} else 0).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_languages = list(train['spoken_languages'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_languages for i in j]).most_common(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['num_languages'] = train['spoken_languages'].apply(lambda x: len(x) if x != {} else 0)\ntrain['all_languages'] = train['spoken_languages'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\ntop_languages = [m[0] for m in Counter([i for j in list_of_languages for i in j]).most_common(30)]\nfor g in top_languages:\n    train['language_' + g] = train['all_languages'].apply(lambda x: 1 if g in x else 0)\n    \ntest['num_languages'] = test['spoken_languages'].apply(lambda x: len(x) if x != {} else 0)\ntest['all_languages'] = test['spoken_languages'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\nfor g in top_languages:\n    test['language_' + g] = test['all_languages'].apply(lambda x: 1 if g in x else 0)\n\ntrain = train.drop(['spoken_languages', 'all_languages'], axis=1)\ntest = test.drop(['spoken_languages', 'all_languages'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, e in enumerate(train['Keywords'][:5]):\n    print(i, e)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of Keywords in films')\ntrain['Keywords'].apply(lambda x: len(x) if x != {} else 0).value_counts().head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_keywords = list(train['Keywords'].apply(lambda x: [i['name'] for i in x] if x!={} else []).values)\nplt.figure(figsize=(16, 12))\ntext = ' '.join(['_'.join(i.split(' ')) for j in list_of_keywords for i in j])\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False, width=1200, height=1000).generate(text)\nplt.imshow(wordcloud)\nplt.title(\"TOP KEYWORDS\")\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['num_Keywords'] = train['Keywords'].apply(lambda x: len(x) if x != {} else 0)\ntrain['all_Keywords'] = train['Keywords'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\ntop_keywords = [m[0] for m in Counter([i for j in list_of_keywords for i in j]).most_common(30)]\nfor g in top_keywords:\n    train['keyword_' + g] = train['all_Keywords'].apply(lambda x: 1 if g in x else 0)\n    \ntest['num_Keywords'] = test['Keywords'].apply(lambda x: len(x) if x != {} else 0)\ntest['all_Keywords'] = test['Keywords'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\nfor g in top_keywords:\n    test['keyword_' + g] = test['all_Keywords'].apply(lambda x: 1 if g in x else 0)\n\ntrain = train.drop(['Keywords', 'all_Keywords'], axis=1)\ntest = test.drop(['Keywords', 'all_Keywords'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, e in enumerate(train['cast'][:1]):\n    print(i, e)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of casted persons in films')\ntrain['cast'].apply(lambda x: len(x) if x != {} else 0).value_counts().head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Those who are casted heavily impact the quality of the film. We have not only the name of the actor, but also the gender and character name/type.\n\nAt first let's have a look at the popular names."},{"metadata":{"trusted":true},"cell_type":"code","source":"# popular names in the films\nlist_of_cast_names = list(train['cast'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_cast_names for i in j]).most_common(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"list of genders"},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_cast_genders = list(train['cast'].apply(lambda x: [i['gender'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_cast_genders for i in j]).most_common()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"0 is unspecified, 1 is female, and 2 is male."},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_cast_characters = list(train['cast'].apply(lambda x: [i['character'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_cast_characters for i in j]).most_common(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"it is quite funny the most popular male role is playing himself. :)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['num_cast'] = train['cast'].apply(lambda x: len(x) if x != {} else 0)\ntop_cast_names = [m[0] for m in Counter([i for j in list_of_cast_names for i in j]).most_common(15)]\nfor g in top_cast_names:\n    train['cast_name_' + g] = train['cast'].apply(lambda x: 1 if g in str(x) else 0)\ntrain['genders_0_cast'] = train['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\ntrain['genders_1_cast'] = train['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\ntrain['genders_2_cast'] = train['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\ntop_cast_characters = [m[0] for m in Counter([i for j in list_of_cast_characters for i in j]).most_common(15)]\nfor g in top_cast_characters:\n    train['cast_character_' + g] = train['cast'].apply(lambda x: 1 if g in str(x) else 0)\n    \ntest['num_cast'] = test['cast'].apply(lambda x: len(x) if x != {} else 0)\nfor g in top_cast_names:\n    test['cast_name_' + g] = test['cast'].apply(lambda x: 1 if g in str(x) else 0)\ntest['genders_0_cast'] = test['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\ntest['genders_1_cast'] = test['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\ntest['genders_2_cast'] = test['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\nfor g in top_cast_characters:\n    test['cast_character_' + g] = test['cast'].apply(lambda x: 1 if g in str(x) else 0)\n\ntrain = train.drop(['cast'], axis=1)\ntest = test.drop(['cast'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"crew"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, e in enumerate(train['crew'][:1]):\n    print(i, e[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of casted persons in films')\ntrain['crew'].apply(lambda x: len(x) if x != {} else 0).value_counts().head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The great crew is very important in creating the film. We have not only the names of the crew members, but also the genders, jobs and departments.\n\nAt first let's have a look at the popular names."},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_crew_names = list(train['crew'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_crew_names for i in j]).most_common(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_crew_jobs = list(train['crew'].apply(lambda x: [i['job'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_crew_jobs for i in j]).most_common(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_crew_genders = list(train['crew'].apply(lambda x: [i['gender'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_crew_genders for i in j]).most_common(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_crew_departments = list(train['crew'].apply(lambda x: [i['department'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_crew_departments for i in j]).most_common(14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_crew_names = train['crew'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values\nCounter([i for j in list_of_crew_names for i in j]).most_common(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['num_crew'] = train['crew'].apply(lambda x: len(x) if x != {} else 0)\ntop_crew_names = [m[0] for m in Counter([i for j in list_of_crew_names for i in j]).most_common(15)]\nfor g in top_crew_names:\n    train['crew_name_' + g] = train['crew'].apply(lambda x: 1 if g in str(x) else 0)\ntrain['genders_0_crew'] = train['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\ntrain['genders_1_crew'] = train['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\ntrain['genders_2_crew'] = train['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\ntop_crew_jobs = [m[0] for m in Counter([i for j in list_of_crew_jobs for i in j]).most_common(15)]\nfor j in top_crew_jobs:\n    train['jobs_' + j] = train['crew'].apply(lambda x: sum([1 for i in x if i['job'] == j]))\ntop_crew_departments = [m[0] for m in Counter([i for j in list_of_crew_departments for i in j]).most_common(15)]\nfor j in top_crew_departments:\n    train['departments_' + j] = train['crew'].apply(lambda x: sum([1 for i in x if i['department'] == j])) \n    \ntest['num_crew'] = test['crew'].apply(lambda x: len(x) if x != {} else 0)\nfor g in top_crew_names:\n    test['crew_name_' + g] = test['crew'].apply(lambda x: 1 if g in str(x) else 0)\ntest['genders_0_crew'] = test['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\ntest['genders_1_crew'] = test['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\ntest['genders_2_crew'] = test['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\nfor j in top_crew_jobs:\n    test['jobs_' + j] = test['crew'].apply(lambda x: sum([1 for i in x if i['job'] == j]))\nfor j in top_crew_departments:\n    test['departments_' + j] = test['crew'].apply(lambda x: sum([1 for i in x if i['department'] == j])) \n\ntrain = train.drop(['crew'], axis=1)\ntest = test.drop(['crew'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Exploration**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (16,6))\nplt.subplot(1, 2, 1)\nplt.hist(train['revenue']);\nplt.title('Distribution of revenue');\nplt.subplot(1, 2, 2)\nplt.hist(np.log1p(train['revenue']));\nplt.title('Distribution of log revenue');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see revenue distribution has a high skewness! It is better to use np.log1p of revenue."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['log_revenue'] = np.log1p(train['revenue'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (16, 6))\nplt.subplot(1, 2, 1)\nplt.hist(train['budget']);\nplt.title('Distribution Of Budget');\n\nplt.subplot(1, 2, 2)\nplt.hist(np.log1p(train['budget']));\nplt.title(\"Distribution of log of Budget\");","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}